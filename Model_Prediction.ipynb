{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedalifaragitiai/Video-captioning-using-deep-learning-with-greedy-search/blob/main/Model_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMwJ4X-T9dxD"
      },
      "source": [
        "# Import  Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLqcrWjbcFk9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFcUjqaW5sWv",
        "outputId": "c476961d-655d-4b84-f791-7aa713884ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# log into drive from colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErTigKzGmzWb",
        "outputId": "d0587a36-b990-471f-c8f5-6bbc9e3a29a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQmuiDqXm8jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yRrX0Kll7Nh"
      },
      "source": [
        "# Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwCejz6ll3ii"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/MyMaster/Final VD/Data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M3EJ77eUCvw",
        "outputId": "d532c8d1-bfde-4c80-dbb1-566f1705f3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AllVideoDescriptions.txt  model.png              video_frames_dict.pickle\n",
            "glove.6B.300d.txt         \u001b[0m\u001b[01;34mTestData\u001b[0m/              word_to_id.pickle\n",
            "id_to_word.pickle         \u001b[01;34mvideo_frame_features\u001b[0m/  \u001b[01;34mYouTubeClips\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JSJpKcNl2Wb"
      },
      "outputs": [],
      "source": [
        "data_path = os.path.dirname(os.getcwd()) + '/Data/'\n",
        "test_videos_path = os.path.dirname(os.getcwd()) + '/Data/TestData/'\n",
        "video_features_path = os.path.dirname(os.getcwd()) + '/Data/video_frame_features/'\n",
        "saved_model_path = '/content/drive/MyDrive/MyMaster/Final VD/Video_Captioning/saved_model/whole_model'\n",
        "effNet_model_path = '/content/drive/MyDrive/MyMaster/Final VD/Video_Captioning/saved_model/effNet'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIcwYOSMbAMV"
      },
      "source": [
        "\n",
        "# Load EfficientNet and Extract frames from video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdYqKdzvdUHc"
      },
      "outputs": [],
      "source": [
        "def extract_frames_from_video(video_name):\n",
        "    path_input = test_videos_path + video_name + \".avi\"\n",
        "\n",
        "    cap = cv2.VideoCapture(path_input)\n",
        "    cap.set(cv2.CAP_PROP_POS_AVI_RATIO, 0)\n",
        "\n",
        "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\n",
        "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    videoFPS = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    buffer = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype(\"uint8\"))\n",
        "\n",
        "    fc = 0\n",
        "    while fc < frameCount:\n",
        "        ret, buffer[fc] = cap.read()\n",
        "        fc += 1\n",
        "\n",
        "    representative_frames = buffer[::videoFPS, :, :, :] # ::videoFPS means for start to end with step # videoFPS\n",
        "\n",
        "    cap.release()\n",
        "    del buffer\n",
        "    del cap\n",
        "\n",
        "    return representative_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUNGALuRmIhL"
      },
      "outputs": [],
      "source": [
        "def save_features_from_video_frames(video_name):\n",
        "    representative_frames = extract_frames_from_video(video_name)\n",
        "    representative_frames = representative_frames / 255\n",
        "    resized_frames = tf.image.resize_with_crop_or_pad(representative_frames, 600, 600)\n",
        "    frames_features = effNet_model.predict(resized_frames)\n",
        "\n",
        "    np.save(video_features_path + video_name, frames_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jemqKZKFjkOC",
        "outputId": "3700c956-d71e-4d6c-a5b9-d15d4ade85ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "effNet_model = keras.models.load_model(effNet_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4blALCPFrphC",
        "outputId": "57f87b1e-0c95-46e7-a7ee-f2cb4c802ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 2560)              64097680  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,097,680\n",
            "Trainable params: 0\n",
            "Non-trainable params: 64,097,680\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "effNet_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGfvTUcDlVAt"
      },
      "source": [
        "# Load Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLlsB20bMIoY"
      },
      "outputs": [],
      "source": [
        "with open(data_path + 'id_to_word.pickle', \"rb\") as handle:\n",
        "    id_to_word = pickle.load(handle)\n",
        "\n",
        "with open(data_path + 'word_to_id.pickle', \"rb\") as handle:\n",
        "    word_to_id = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBMgWd53t8iD"
      },
      "outputs": [],
      "source": [
        "words = tf.constant(list(id_to_word.values()))\n",
        "word_ids = tf.constant(list(word_to_id.values()), dtype=tf.int64)\n",
        "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
        "num_oov_buckets = 1\n",
        "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0Ond93YOsTd"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(words)\n",
        "id_to_word[len(id_to_word)] = \"<unk>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA0q6CGft8ih"
      },
      "source": [
        "## Data Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4JUjB5lWjTj"
      },
      "outputs": [],
      "source": [
        "def padding_part_of_caption_sequence(video_length):\n",
        "    return video_length * [\"<pad>\"]\n",
        "\n",
        "def append_bos_token(sequence_list):\n",
        "    return sequence_list + [\"<bos>\"]\n",
        "\n",
        "def append_eos_token(sequence_list):\n",
        "    return sequence_list + [\"<eos>\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKnz1-J1t8im"
      },
      "outputs": [],
      "source": [
        "# load video features array and pad it, return padded features\n",
        "def get_padded_input_cnn(video_name, caption_length):\n",
        "    stored_features_path = video_features_path + video_name + \".npy\"\n",
        "    features_array = np.load(stored_features_path)\n",
        "    Number_of_frames = features_array.shape[0]\n",
        "\n",
        "    input_cnn_padding_length = caption_length + 1\n",
        "    input_cnn_padding_array = np.full([input_cnn_padding_length, 2560], 0)\n",
        "    input_cnn_padded_array = np.concatenate((features_array, input_cnn_padding_array))\n",
        "    return tf.constant(input_cnn_padded_array), Number_of_frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gWNfg9Ot8is"
      },
      "source": [
        "# Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTGEJsaCSI98"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgOqOgB5t8iw"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osmvzeBaezM_"
      },
      "outputs": [],
      "source": [
        "# tf.keras.utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTsZG7ZIsjsH"
      },
      "source": [
        "# Enter Video Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rdpqUgNsnye"
      },
      "outputs": [],
      "source": [
        "videoName = \"testVideo8\"\n",
        "#testVideo4 && testVideo7 && testVideo2 && testVideo1 && testVideo8 && testVideo9 && testVideo10 && testVideo11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWJr-IW6sHFZ"
      },
      "source": [
        "# Extract video frame features using an EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRbPYV6BsLLM"
      },
      "outputs": [],
      "source": [
        "_, _, features_files = next(os.walk(video_features_path))\n",
        "features_files = [x[:-4] for x in features_files]\n",
        "unprocessed_video_names = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd0heCVxsPyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdedc27d-e957-4c69-f43a-5894567079cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 5s 4s/step\n"
          ]
        }
      ],
      "source": [
        "if (videoName not in features_files):\n",
        "    try:\n",
        "        save_features_from_video_frames(videoName)\n",
        "        features_files.append(videoName)\n",
        "    except:\n",
        "        unprocessed_video_names.append(videoName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydnF7Sh3t8ix"
      },
      "source": [
        "# Inference (Greedy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgamrLO5t8jB"
      },
      "outputs": [],
      "source": [
        "sample_cnn_input, Number_of_frames = get_padded_input_cnn(videoName, 20)\n",
        "\n",
        "input_seq = table.lookup(\n",
        "    tf.constant(\n",
        "        append_bos_token(\n",
        "            padding_part_of_caption_sequence(Number_of_frames)\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOUG4XS8t8jB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2df312-3aa1-4eb2-c173-2f7b72503adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        }
      ],
      "source": [
        "initial_input_seq_length = len(input_seq)\n",
        "END_TOKEN = 2\n",
        "\n",
        "next_token = -1\n",
        "for i in range(20):\n",
        "    next_token = model.predict(\n",
        "        (\n",
        "            tf.expand_dims(sample_cnn_input[: len(input_seq)], axis=0),\n",
        "            tf.expand_dims(input_seq, axis=0),\n",
        "        )\n",
        "    )[0][-1].argmax()\n",
        "\n",
        "    if next_token == END_TOKEN:\n",
        "        break\n",
        "\n",
        "    input_seq = tf.concat(\n",
        "        [tf.cast(input_seq, tf.int32), tf.cast(tf.constant([next_token]), tf.int32)],\n",
        "        axis=-1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dvLQDXBt8jC",
        "outputId": "b0ee5343-7b58-4fc6-eac0-5fa053cb6d97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'cat', 'is', 'playing']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "[id_to_word[id_] for id_ in input_seq[initial_input_seq_length:].numpy().tolist()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM-ZKk7j31XC"
      },
      "source": [
        "# Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u--MgeLXbgCM"
      },
      "outputs": [],
      "source": [
        "# with probabilities\n",
        "beam_width = 10\n",
        "maximum_caption_length = 10\n",
        "\n",
        "sample_cnn_input, Number_of_frames = get_padded_input_cnn(videoName, maximum_caption_length)\n",
        "\n",
        "input_seq = table.lookup(\n",
        "    tf.constant(\n",
        "        append_bos_token(\n",
        "            padding_part_of_caption_sequence(Number_of_frames)\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNrqKnCPhMsV"
      },
      "outputs": [],
      "source": [
        "initial_input_seq_length = len(input_seq)\n",
        "certainty_lists = [[] for _ in range(beam_width)]\n",
        "sentences = [input_seq for _ in range(beam_width)]\n",
        "sentence_probabilities = [1 for _ in range(beam_width)]\n",
        "END_TOKEN = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR42EZG-4EBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79671c1b-5608-4643-a900-10f748c9e4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n"
          ]
        }
      ],
      "source": [
        "for i in range(maximum_caption_length):\n",
        "    if i == 0:\n",
        "        prediction = model.predict(\n",
        "            (\n",
        "                tf.expand_dims(sample_cnn_input[: len(input_seq)], axis=0),\n",
        "                tf.expand_dims(input_seq, axis=0),\n",
        "            )\n",
        "        )[0][-1] # last token in sequence probability\n",
        "\n",
        "        next_tokens = prediction.argsort()[-beam_width:][::-1]\n",
        "        for j in range(beam_width):\n",
        "            sentences[j] = tf.concat(\n",
        "                [\n",
        "                    tf.cast(sentences[j], tf.int32),\n",
        "                    tf.cast(tf.constant([next_tokens[j]]), tf.int32),\n",
        "                ],\n",
        "                axis=-1,\n",
        "            )\n",
        "            sentence_probabilities[j] = (sentence_probabilities[j] * prediction[next_tokens[j]])\n",
        "            certainty_lists[j].append(prediction[next_tokens[j]])\n",
        "\n",
        "    if i > 0:\n",
        "        next_sentences = sentences.copy()\n",
        "        next_certainty_lists = [[] for _ in range(beam_width)]\n",
        "        next_token_probabilities = [[] for _ in range(beam_width)]\n",
        "        next_sentence_probabilities = [[] for _ in range(beam_width)]\n",
        "\n",
        "        for j in range(beam_width):\n",
        "            prediction = model.predict(\n",
        "                (\n",
        "                    tf.expand_dims(sample_cnn_input[: len(sentences[j])], axis=0),\n",
        "                    tf.expand_dims(sentences[j], axis=0),\n",
        "                )\n",
        "            )[0][-1]\n",
        "\n",
        "            next_sentence_probabilities[j] = prediction * sentence_probabilities[j]\n",
        "            next_token_probabilities[j] = prediction\n",
        "\n",
        "        # np.dstack make (concat, stack and block)\n",
        "        indices_of_most_probable_sentences = np.dstack(\n",
        "            np.unravel_index(\n",
        "                np.argsort(np.array(next_sentence_probabilities).ravel()),\n",
        "                (beam_width, vocab_size + num_oov_buckets),\n",
        "        ))[0][-beam_width:][::-1]   # shape before slice (1, #beam_width * #(vocab_size + num_oov_buckets), # beam_width)\n",
        "\n",
        "        for k in range(beam_width):\n",
        "            next_sentence_index = indices_of_most_probable_sentences[k][0]\n",
        "            next_token_index = indices_of_most_probable_sentences[k][1]\n",
        "            next_sentences[k] = tf.concat(\n",
        "                [\n",
        "                    tf.cast(sentences[next_sentence_index], tf.int32),\n",
        "                    tf.cast(tf.constant([next_token_index]), tf.int32),\n",
        "                ],\n",
        "                axis=-1,\n",
        "            )\n",
        "\n",
        "            sentence_probabilities[k] = next_sentence_probabilities[next_sentence_index][next_token_index]\n",
        "\n",
        "            next_certainty_lists[k] = certainty_lists[next_sentence_index].copy()\n",
        "            next_certainty_lists[k].append(next_token_probabilities[next_sentence_index][next_token_index])\n",
        "\n",
        "        sentences = next_sentences\n",
        "        certainty_lists = next_certainty_lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCkdpPmJ4FZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2223325c-4081-4d1f-eb1f-a644ddc70738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'cat', 'is', 'playing']\n",
            "Sentence probability: 0.0011712479 \n",
            "\n",
            "a \t 0.7833383\n",
            "cat \t 0.16917801\n",
            "is \t 0.8747256\n",
            "playing \t 0.09724133\n",
            "\n",
            "\n",
            "['a', 'small', 'group', 'of', 'kids', 'are', 'playing']\n",
            "Sentence probability: 0.0009851756 \n",
            "\n",
            "a \t 0.7833383\n",
            "small \t 0.1205752\n",
            "group \t 0.30174574\n",
            "of \t 0.99583995\n",
            "kids \t 0.14416866\n",
            "are \t 0.71174026\n",
            "playing \t 0.9530341\n",
            "\n",
            "\n",
            "['a', 'cat', 'is', 'playing']\n",
            "Sentence probability: 0.0009255728 \n",
            "\n",
            "a \t 0.7833383\n",
            "cat \t 0.16917801\n",
            "is \t 0.8747256\n",
            "playing \t 0.09724133\n",
            "\n",
            "\n",
            "['a', 'small', 'group', 'of', 'people', 'are', 'playing']\n",
            "Sentence probability: 0.00087840436 \n",
            "\n",
            "a \t 0.7833383\n",
            "small \t 0.1205752\n",
            "group \t 0.30174574\n",
            "of \t 0.99583995\n",
            "people \t 0.26272553\n",
            "are \t 0.7720742\n",
            "playing \t 0.83425546\n",
            "\n",
            "\n",
            "['a', 'cat', 'is', 'playing']\n",
            "Sentence probability: 0.0008031002 \n",
            "\n",
            "a \t 0.7833383\n",
            "cat \t 0.16917801\n",
            "is \t 0.8747256\n",
            "playing \t 0.09724133\n",
            "\n",
            "\n",
            "['a', 'cat', 'is', 'meowing']\n",
            "Sentence probability: 0.0007846419 \n",
            "\n",
            "a \t 0.7833383\n",
            "cat \t 0.16917801\n",
            "is \t 0.8747256\n",
            "meowing \t 0.073722064\n",
            "\n",
            "\n",
            "['a', 'person', 'is', 'playing', 'with', 'a', 'toy']\n",
            "Sentence probability: 0.00064938323 \n",
            "\n",
            "a \t 0.7833383\n",
            "person \t 0.0606776\n",
            "is \t 0.7266202\n",
            "playing \t 0.24830703\n",
            "with \t 0.85196316\n",
            "a \t 0.3811027\n",
            "toy \t 0.47413233\n",
            "\n",
            "\n",
            "['a', 'small', 'group', 'of', 'kids', 'are', 'playing']\n",
            "Sentence probability: 0.00039375844 \n",
            "\n",
            "a \t 0.7833383\n",
            "small \t 0.1205752\n",
            "group \t 0.30174574\n",
            "of \t 0.99583995\n",
            "kids \t 0.14416866\n",
            "are \t 0.71174026\n",
            "playing \t 0.9530341\n",
            "\n",
            "\n",
            "['a', 'small', 'group', 'of', 'kids', 'are', 'playing']\n",
            "Sentence probability: 0.00030603708 \n",
            "\n",
            "a \t 0.7833383\n",
            "small \t 0.1205752\n",
            "group \t 0.30174574\n",
            "of \t 0.99583995\n",
            "kids \t 0.14416866\n",
            "are \t 0.71174026\n",
            "playing \t 0.9530341\n",
            "\n",
            "\n",
            "['a', 'small', 'group', 'of', 'kids', 'are', 'playing']\n",
            "Sentence probability: 0.00030199523 \n",
            "\n",
            "a \t 0.7833383\n",
            "small \t 0.1205752\n",
            "group \t 0.30174574\n",
            "of \t 0.99583995\n",
            "kids \t 0.14416866\n",
            "are \t 0.71174026\n",
            "playing \t 0.9530341\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(beam_width):\n",
        "    try:\n",
        "        stop_index = sentences[i][initial_input_seq_length:].numpy().tolist().index(END_TOKEN)\n",
        "        predicted_caption = [id_to_word[id_] for id_ in sentences[i][initial_input_seq_length:]\n",
        "                            .numpy().tolist()[:stop_index]]\n",
        "    except:\n",
        "        predicted_caption = [id_to_word[id_] for id_ in sentences[i][initial_input_seq_length:]\n",
        "                            .numpy().tolist()]\n",
        "\n",
        "    print(predicted_caption)\n",
        "    print(\"Sentence probability:\", sentence_probabilities[i], '\\n')\n",
        "\n",
        "    for word, certainty in zip(predicted_caption, certainty_lists[i]):\n",
        "        print(word, '\\t', certainty)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuH410Ul0p8T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "0fedbd03237c4841a14b50efbfd66476bd397e867548a8d33590bc43b97ae133"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}